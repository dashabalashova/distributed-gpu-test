name: SLURM CI – build -> test -> push

on:
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: read
  packages: write
  id-token: write

env:
  IMAGE_NAME: ghcr.io/dashabalashova/distributed-gpu-test
  REMOTE_DIR: /root/distributed-gpu-test

jobs:
  build:
    name: Build image
    runs-on: [self-hosted, docker-host]
    outputs:
      image-tag: ${{ steps.set-tag.outputs.image_tag }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set IMAGE_TAG
        id: set-tag
        run: |
          IMAGE_TAG="v0.1.0"
          echo "IMAGE_TAG=$IMAGE_TAG" >> $GITHUB_ENV
          echo "image_tag=$IMAGE_TAG" >> $GITHUB_OUTPUT

      - name: Set up QEMU and buildx
        uses: docker/setup-buildx-action@v2

      - name: Build docker image (load into local docker daemon)
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: false
          load: true
          tags: ${{ env.IMAGE_NAME }}:${{ steps.set-tag.outputs.image_tag }}

      - name: Create enroot squashfs (.sqsh) from local Docker image
        run: |
          set -euo pipefail
          SQSH_NAME="distributed-gpu-test.sqsh"
          echo "Creating enroot squashfs: $SQSH_NAME from ${{ env.IMAGE_NAME }}:${{ steps.set-tag.outputs.image_tag }}"
          enroot import --output "$SQSH_NAME" "dockerd://${{ env.IMAGE_NAME }}:${{ steps.set-tag.outputs.image_tag }}"
          echo "SQSH_NAME=$SQSH_NAME" >> $GITHUB_ENV

      - name: Ensure remote dir exists (on SLURM host)
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ secrets.SLURM_HOST }}
          username: ${{ secrets.SLURM_USER }}
          key: ${{ secrets.SLURM_SSH_KEY }}
          port: ${{ secrets.SLURM_SSH_PORT }}
          script: |
            mkdir -p "${{ env.REMOTE_DIR }}"

      - name: slurm_train.sbatch and train.py to SLURM host
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.SLURM_HOST }}
          username: ${{ secrets.SLURM_USER }}
          key: ${{ secrets.SLURM_SSH_KEY }}
          port: ${{ secrets.SLURM_SSH_PORT }}
          source: "slurm_train.sbatch,train.py"
          target: "${{ env.REMOTE_DIR }}"
          strip_components: 0

      - name: Copy .sqsh to SLURM host with rsync (shows progress)
        env:
          SLURM_SSH_PORT: ${{ secrets.SLURM_SSH_PORT }}
          SLURM_SSH_KEY: ${{ secrets.SLURM_SSH_KEY }}
          SLURM_USER: ${{ secrets.SLURM_USER }}
          SLURM_HOST: ${{ secrets.SLURM_HOST }}
          REMOTE_DIR: ${{ env.REMOTE_DIR }}
        run: |
          set -euo pipefail
          mkdir -p ~/.ssh

          printf '%s\n' "$SLURM_SSH_KEY" > ~/.ssh/slurm_key
          chmod 600 ~/.ssh/slurm_key

          rsync -avP -e "ssh -i ~/.ssh/slurm_key -p "${{ secrets.SLURM_SSH_PORT }}" -o StrictHostKeyChecking=no" \
            distributed-gpu-test.sqsh \
            "${SLURM_USER}@${SLURM_HOST}:${REMOTE_DIR}"
        shell: bash

  test-on-slurm:
    name: Test on remote SLURM
    needs: build
    runs-on: [self-hosted, docker-host]
    steps:
      - id: run_teset
        name: Run remote test – submit slurm job and wait
        uses: appleboy/ssh-action@v0.1.7
        with:
          host: ${{ secrets.SLURM_HOST }}
          username: ${{ secrets.SLURM_USER }}
          key: ${{ secrets.SLURM_SSH_KEY }}
          port: ${{ secrets.SLURM_SSH_PORT }}
          script: |
            #!/bin/bash
            set -euo pipefail
        
            REMOTE_DIR="${{ env.REMOTE_DIR }}"
            mkdir -p "$REMOTE_DIR"
            cd "$REMOTE_DIR"

            NODES=$(scontrol show nodes | grep -c '^NodeName')
            GPUS=$(scontrol show nodes | sed -n 's/.*CfgTRES=.*gres\/gpu=\([0-9][0-9]*\).*/\1/p' | head -n1)
            sed -e "s/^#SBATCH --nodes=.*/#SBATCH --nodes=${NODES}/" \
                -e "s/^#SBATCH --gres=gpu:.*/#SBATCH --gres=gpu:${GPUS}/" \
                slurm_train.sbatch > slurm_train.submit.sbatch
            rm -f "$PWD/job_status.txt"
            SBATCH_OUT=$(sbatch --export=ALL,GPUS_PER_NODE="$GPUS",NNODES="$NODES" slurm_train.submit.sbatch)
            
            if [ -z "$SBATCH_OUT" ]; then
              echo "Failed to submit job; sbatch output: $SBATCH_OUT"
              exit 2
            fi
            JOB_ID=$(echo "$SBATCH_OUT" | awk '{print $NF}')
            echo "Submitted batch job $JOB_ID"

            JOB_POLL_INTERVAL=10
            JOB_POLL_MAX=30
            
            echo "Polling squeue for job $JOB_ID (every ${JOB_POLL_INTERVAL}s, up to ${JOB_POLL_MAX} attempts)..."
            
            STATE=""
            for (( i=0; i<JOB_POLL_MAX; i++ )); do
              STATE=$(squeue -j "$JOB_ID" -h -o "%T" 2>/dev/null | tr -d '\r' || true)
              if [ -z "$STATE" ]; then
                echo "Job $JOB_ID no longer in squeue (checked $((i+1)) times)"
                break
              fi
              echo "Job $JOB_ID state: $STATE — sleeping ${JOB_POLL_INTERVAL}s..."
              sleep "$JOB_POLL_INTERVAL"
            done
            
            if [ -n "$STATE" ]; then
              echo "Job $JOB_ID still in squeue after $((JOB_POLL_MAX * JOB_POLL_INTERVAL)) seconds; cancelling and exiting."
              scancel "$JOB_ID" || true
              exit 124
            fi
            
            STATUS_FILE="$PWD/job_status.txt"
            STATUS_POLL_INTERVAL=10
            STATUS_POLL_MAX=3
            
            echo "Waiting for status file $STATUS_FILE (every ${STATUS_POLL_INTERVAL}s, up to ${STATUS_POLL_MAX} attempts)..."
            
            for (( j=0; j<STATUS_POLL_MAX; j++ )); do
              if [ -f "$STATUS_FILE" ]; then
                STATUS=$(cat "$STATUS_FILE" | tr -d '\r' || true)
                echo "Found $STATUS_FILE -> '$STATUS'"
                case "$STATUS" in
                  success|0)
                    exit 0
                    ;;
                  fail|1)
                    echo "Remote job reported fail"
                    exit 1
                    ;;
                  *)
                    echo "Unknown status file content: '$STATUS' — treating as failure"
                    exit 1
                    ;;
                esac
              fi
              echo "Status file not present yet — sleeping ${STATUS_POLL_INTERVAL}s..."
              sleep "$STATUS_POLL_INTERVAL"
            done
            
            echo "$STATUS_FILE did not appear after $((STATUS_POLL_MAX * STATUS_POLL_INTERVAL)) seconds — treating as failure"
            exit 1

      - id: set_slurm_status
        name: Set job output based on previous step
        if: ${{ success() }}
        run: |
          echo "slurm_status=success"
          echo "slurm_status=success" >> $GITHUB_OUTPUT

      - id: set_slurm_status_fail
        name: Set job output on failure
        if: ${{ failure() }}
        run: |
          echo "slurm_status=failed"
          echo "slurm_status=failed" >> $GITHUB_OUTPUT

    outputs:
      slurm_status: ${{ steps.set_slurm_status.outputs.slurm_status }}
            
  publish:
      name: Publish image to GHCR (only if SLURM job success)
      needs: [build, test-on-slurm]
      runs-on: [self-hosted, docker-host]
      env:
        IMAGE_NAME: ghcr.io/dashabalashova/distributed-gpu-test
        IMAGE_TAG: ${{ needs.build.outputs.image-tag }}
    
      steps:
        - name: Debug show slurm_status from needs
          shell: bash
          run: |
            echo "RAW needs.test-on-slurm.outputs.slurm_status: >>>${{ needs['test-on-slurm'].outputs.slurm_status }}<<<"
    
            SLURM_STATUS="${{ needs['test-on-slurm'].outputs.slurm_status }}"
            SLURM_STATUS="${SLURM_STATUS//$'\r'/}"
            SLURM_STATUS="$(echo -n "$SLURM_STATUS" | sed -e 's/^[[:space:]]*//' -e 's/[[:space:]]*$//')"
    
            echo "as shell var: '${SLURM_STATUS}'"
            printf "len=%d\n" "${#SLURM_STATUS}"
    
        - name: Ensure image exists locally and push to GHCR
          if: ${{ needs['test-on-slurm'].outputs.slurm_status == 'success' }}
          env:
            CR_PAT: ${{ secrets.CR_PAT }}
          run: |
            set -euo pipefail
            TAG="${IMAGE_NAME}:${IMAGE_TAG}"
            echo "Logging in to ghcr.io"
            echo "${CR_PAT}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin
            echo "Pushing $TAG"
            docker push "$TAG"
